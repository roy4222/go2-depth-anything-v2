"""
Perception Server V2 - YOLO-World + Depth Anything V2 èåˆ
ç”¨é€”: æ¥æ”¶åœ–ç‰‡ï¼Œå›å‚³ç‰©ä»¶åµæ¸¬ + æ·±åº¦ä¼°è¨ˆ + å°èˆªæŒ‡ä»¤

API ç«¯é»:
- /perceive     - æ·±åº¦ä¼°è¨ˆèˆ‡é¿éšœå»ºè­° (åŸæœ‰)
- /find_object  - ç‰©ä»¶åµæ¸¬ + è·é›¢ä¼°è¨ˆ + å°èˆªæŒ‡ä»¤ (æ–°å¢)
"""

from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import JSONResponse
import torch
import numpy as np
from PIL import Image
import io
import sys
import os
import time

# åŠ å…¥ Depth Anything V2 metric_depth è·¯å¾‘
DA3_ROOT = os.path.expanduser("~/Depth_Anything_V2/Depth-Anything-V2")
sys.path.insert(0, os.path.join(DA3_ROOT, 'metric_depth'))
from depth_anything_v2.dpt import DepthAnythingV2

# YOLO-World
from ultralytics import YOLO

app = FastAPI(
    title="Perception Server V2",
    description="YOLO-World + DA3 èåˆæ„ŸçŸ¥ API - ç‚º Go2 æ©Ÿå™¨ç‹—æä¾›ç‰©ä»¶åµæ¸¬èˆ‡å°èˆª",
    version="2.0.0"
)

# ======================
# å…¨åŸŸæ¨¡å‹ç‰©ä»¶
# ======================
depth_model = None
yolo_model = None
device = None

# ======================
# æ ¡æ­£åƒæ•¸ (Go2 å»£è§’é¡é ­)
# ======================
SCALE_FACTOR = 0.60      # DA3 è·é›¢æ ¡æ­£
IMAGE_WIDTH = 640        # ç•«é¢å¯¬åº¦
LEFT_THRESHOLD = 213     # å·¦å´å€åŸŸ (< 1/3)
RIGHT_THRESHOLD = 427    # å³å´å€åŸŸ (> 2/3)


@app.on_event("startup")
async def load_models():
    """ä¼ºæœå™¨å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡å‹"""
    global depth_model, yolo_model, device
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ è£ç½®: {device}")
    
    # === è¼‰å…¥ Depth Anything V2 ===
    print("ğŸ”„ æ­£åœ¨è¼‰å…¥ Depth Anything V2...")
    depth_model = DepthAnythingV2(
        encoder='vitl',
        features=256,
        out_channels=[256, 512, 1024, 1024],
        max_depth=20.0
    )
    
    checkpoint_path = os.path.join(
        DA3_ROOT, 
        'checkpoints', 
        'depth_anything_v2_metric_hypersim_vitl.pth'
    )
    
    if os.path.exists(checkpoint_path):
        depth_model.load_state_dict(
            torch.load(checkpoint_path, map_location=device), 
            strict=False
        )
        depth_model = depth_model.to(device).eval()
        print("âœ… DA3 æ¨¡å‹è¼‰å…¥å®Œæˆ")
    else:
        print(f"âš ï¸ DA3 æ¬Šé‡ä¸å­˜åœ¨: {checkpoint_path}")
    
    # === è¼‰å…¥ YOLO-World ===
    print("ğŸ”„ æ­£åœ¨è¼‰å…¥ YOLO-World...")
    yolo_path = os.path.join(os.path.dirname(__file__), 'yolov8l-worldv2.pt')
    
    if not os.path.exists(yolo_path):
        # å‚™ç”¨è·¯å¾‘
        yolo_path = "/home/roy422/Yoloworld/yolov8l-worldv2.pt"
    
    yolo_model = YOLO(yolo_path)
    yolo_model.to(device)
    yolo_model.set_classes(["person", "chair", "table", "obstacle"])  # é è¨­
    print("âœ… YOLO-World æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    vram = torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0
    print(f"ğŸš€ æ‰€æœ‰æ¨¡å‹å°±ç·’ (VRAM: {vram:.2f} GB)")


def get_direction(cx: float) -> tuple[str, float]:
    """
    æ ¹æ“šç‰©ä»¶ä¸­å¿ƒé»åˆ¤æ–·æ–¹å‘èˆ‡è§’é€Ÿåº¦
    
    Returns:
        (direction, angular_z)
    """
    if cx < LEFT_THRESHOLD:
        return "å·¦å´", 0.3
    elif cx > RIGHT_THRESHOLD:
        return "å³å´", -0.3
    else:
        return "æ­£å‰æ–¹", 0.0


def generate_cmd_vel(direction: str, distance: float, angular_z: float) -> dict:
    """
    ç”¢ç”Ÿ cmd_vel æŒ‡ä»¤
    
    è·é›¢è¶Šé  linear.x è¶Šå¤§ï¼Œå¤ªè¿‘å‰‡åœæ­¢
    """
    if distance < 0.3:
        # å¤ªè¿‘ï¼Œåœæ­¢
        return {"linear_x": 0.0, "angular_z": 0.0}
    elif distance < 1.0:
        # é è¿‘ä¸­ï¼Œæ…¢é€Ÿ
        return {"linear_x": 0.1, "angular_z": angular_z}
    else:
        # æ­£å¸¸è·é›¢
        return {"linear_x": 0.2, "angular_z": angular_z}


# ======================
# API: å¥åº·æª¢æŸ¥
# ======================
@app.get("/")
async def root():
    return {
        "status": "ok",
        "version": "2.0.0",
        "models": {
            "depth": depth_model is not None,
            "yolo": yolo_model is not None
        },
        "device": str(device)
    }


# ======================
# API: ç‰©ä»¶æœå°‹ + æ·±åº¦ + å°èˆª
# ======================
@app.post("/find_object")
async def find_object(
    image: UploadFile = File(...),
    target: str = Form(default="water bottle"),
    conf: float = Form(default=0.25)
):
    """
    èåˆ YOLO + DA3 çš„ç‰©ä»¶æœå°‹ API
    
    Args:
        image: ä¸Šå‚³çš„åœ–ç‰‡
        target: æœå°‹ç›®æ¨™ (å¯ç”¨é€—è™Ÿåˆ†éš”å¤šå€‹)
        conf: ä¿¡å¿ƒåº¦é–¾å€¼
        
    Returns:
        JSON åŒ…å«åµæ¸¬çµæœã€è·é›¢ã€æ–¹å‘ã€cmd_vel
    """
    if yolo_model is None or depth_model is None:
        return JSONResponse(
            status_code=503,
            content={"error": "æ¨¡å‹å°šæœªè¼‰å…¥å®Œæˆ"}
        )
    
    start_time = time.time()
    
    try:
        # 1. è®€å–åœ–ç‰‡
        contents = await image.read()
        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
        raw_image = np.array(pil_image)
        
        # 2. è¨­å®š YOLO ç›®æ¨™é¡åˆ¥
        targets = [t.strip() for t in target.split(",")]
        yolo_model.set_classes(targets)
        
        # 3. YOLO åµæ¸¬
        yolo_start = time.time()
        results = yolo_model(pil_image, conf=conf)
        yolo_time = (time.time() - yolo_start) * 1000
        
        # 4. DA3 æ·±åº¦ä¼°è¨ˆ
        depth_start = time.time()
        with torch.no_grad():
            depth_map = depth_model.infer_image(raw_image)
        depth_time = (time.time() - depth_start) * 1000
        
        # 5. èåˆçµæœ
        response = {
            "found": False,
            "target": target,
            "results": [],
            "timing_ms": {
                "yolo": round(yolo_time, 1),
                "depth": round(depth_time, 1),
                "total": round((time.time() - start_time) * 1000, 1)
            }
        }
        
        if len(results) > 0 and len(results[0].boxes) > 0:
            for box in results[0].boxes:
                # åº§æ¨™
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                cx = int((x1 + x2) / 2)
                cy = int((y1 + y2) / 2)
                
                # é¡åˆ¥èˆ‡ä¿¡å¿ƒåº¦
                cls_id = int(box.cls)
                label = yolo_model.names[cls_id]
                score = float(box.conf)
                
                # å¾æ·±åº¦åœ–å–å¾—è·é›¢ (æ³¨æ„: depth_map[y, x] ä¸æ˜¯ [x, y])
                if 0 <= cy < depth_map.shape[0] and 0 <= cx < depth_map.shape[1]:
                    raw_distance = float(depth_map[cy, cx])
                    distance = raw_distance * SCALE_FACTOR
                else:
                    distance = -1  # ç„¡æ³•å–å¾—
                
                # æ–¹å‘èˆ‡å°èˆªæŒ‡ä»¤
                direction, angular_z = get_direction(cx)
                cmd_vel = generate_cmd_vel(direction, distance, angular_z)
                
                response["results"].append({
                    "label": label,
                    "confidence": round(score, 3),
                    "distance_m": round(distance, 2),
                    "direction": direction,
                    "center": [cx, cy],
                    "bbox": [int(x1), int(y1), int(x2-x1), int(y2-y1)],
                    "cmd_vel": cmd_vel
                })
            
            if len(response["results"]) > 0:
                response["found"] = True
                # æŒ‰è·é›¢æ’åºï¼Œæœ€è¿‘çš„å„ªå…ˆ
                response["results"].sort(key=lambda x: x["distance_m"])
        
        return response
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"è™•ç†å¤±æ•—: {str(e)}"}
        )


# ======================
# API: ç°¡åŒ–ç‰ˆ (åªå›æœ€è¿‘çš„ç‰©ä»¶)
# ======================
@app.post("/find_object/summary")
async def find_object_summary(
    image: UploadFile = File(...),
    target: str = Form(default="water bottle"),
    conf: float = Form(default=0.25)
):
    """å›å‚³æœ€è¿‘ä¸€å€‹ç‰©ä»¶çš„æ‘˜è¦ï¼ˆçµ¦ LLM ç”¨ï¼‰"""
    result = await find_object(image, target, conf)
    
    if isinstance(result, JSONResponse):
        return result
    
    if not result["found"]:
        return {"message": f"æ‰¾ä¸åˆ° {target}"}
    
    nearest = result["results"][0]
    return {
        "found": True,
        "label": nearest["label"],
        "distance_m": nearest["distance_m"],
        "direction": nearest["direction"],
        "cmd_vel": nearest["cmd_vel"],
        "message": f"ç™¼ç¾ {nearest['label']} åœ¨{nearest['direction']}ï¼Œè·é›¢ {nearest['distance_m']:.1f} å…¬å°º"
    }


# ======================
# API: åŸæœ‰æ·±åº¦åˆ†æ (ä¿ç•™ç›¸å®¹æ€§)
# ======================
def analyze_depth_regions(depth_map: np.ndarray) -> dict:
    h, w = depth_map.shape
    left_region = depth_map[:, :w//3]
    center_region = depth_map[:, w//3:2*w//3]
    right_region = depth_map[:, 2*w//3:]
    
    left_dist = float(np.median(left_region)) * SCALE_FACTOR
    center_dist = float(np.median(center_region)) * SCALE_FACTOR
    right_dist = float(np.median(right_region)) * SCALE_FACTOR
    
    center_lower = depth_map[h//2:, w//3:2*w//3]
    center_front = float(np.percentile(center_lower, 25)) * SCALE_FACTOR
    
    return {
        "left_m": round(left_dist, 2),
        "center_m": round(center_dist, 2),
        "right_m": round(right_dist, 2),
        "front_obstacle_m": round(center_front, 2),
    }


@app.post("/perceive")
async def perceive(
    image: UploadFile = File(...),
    obstacle_threshold: float = 1.0
):
    """åŸæœ‰çš„æ·±åº¦æ„ŸçŸ¥ API (ä¿ç•™ç›¸å®¹æ€§)"""
    if depth_model is None:
        return JSONResponse(
            status_code=503,
            content={"error": "æ¨¡å‹å°šæœªè¼‰å…¥å®Œæˆ"}
        )
    
    start_time = time.time()
    
    try:
        contents = await image.read()
        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
        raw_image = np.array(pil_image)
        
        with torch.no_grad():
            depth_map = depth_model.infer_image(raw_image)
        
        regions = analyze_depth_regions(depth_map)
        elapsed_ms = (time.time() - start_time) * 1000
        
        return {
            **regions,
            "inference_ms": round(elapsed_ms, 1)
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"è™•ç†å¤±æ•—: {str(e)}"}
        )


# ======================
# ç›´æ¥é‹è¡Œ (é–‹ç™¼ç”¨)
# ======================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
