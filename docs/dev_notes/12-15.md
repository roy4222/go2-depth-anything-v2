# 2025-12-15 開發筆記 (W8 Day 1)

**日期：** 2025/12/15（星期日）  
**目標：** W8 感知系統整合啟動 - FastAPI Server + 距離校正  
**前置作業：** W7 視覺閉環 Phase A-D 全部完成 ✅  
**關鍵里程碑：** 2026/1/7 第一階段發表（剩餘 23 天）

---

## ⏱️ 今日時間軸規劃

| 時段 | 任務 | 主要工作 | 預估時間 |
|------|------|---------|---------|
| 早上 | Task 1 | FastAPI Perception Server 骨架建立 | 2 小時 |
| 下午 | Task 2 | Go2 實拍校正圖（1m/2m/3m） | 1.5 小時 |
| 傍晚 | Task 3 | 距離校正 + 避障建議驗證 | 1.5 小時 |
| 晚上 | Task 4 | 錄製 Demo 備案影片（重要！） | 1 小時 |

**預估總時間：** 5-6 小時

---

## 🎯 今日任務（按優先級）

### 🔴 P0 必須完成

#### Task 1: FastAPI Perception Server（GPU 伺服器）

**目標：** 在 GPU 伺服器建立 `/perceive` 端點，輸入圖片 → 輸出深度摘要

**驗收標準：**
- [ ] Server 啟動無報錯
- [ ] POST `/perceive` 回傳 JSON
- [ ] 回應時間 < 500ms

**檔案位置：** `~/Depth_Anything_V2/perception_server/`

**基本架構：**

```python
# perception_server.py
from fastapi import FastAPI, File, UploadFile
import torch
import sys
sys.path.insert(0, '../Depth-Anything-V2/metric_depth')
from depth_anything_v2.dpt import DepthAnythingV2

app = FastAPI()
model = None  # 預載權重

@app.on_event("startup")
async def load_models():
    global model
    model = DepthAnythingV2(
        encoder='vitl', features=256, 
        out_channels=[256,512,1024,1024], max_depth=20.0
    )
    model.load_state_dict(torch.load(
        '../Depth-Anything-V2/checkpoints/depth_anything_v2_metric_hypersim_vitl.pth'
    ), strict=False)
    model = model.cuda().eval()
    print("✅ DA3 模型載入完成")

@app.post("/perceive")
async def perceive(image: UploadFile = File(...)):
    # 1. 讀取圖片
    # 2. 推論深度
    # 3. 區域分析
    # 4. 回傳 JSON
    return {
        "left_m": 1.5,
        "center_m": 0.8,
        "right_m": 2.3,
        "suggestion": "⚠️ 正前方有障礙，建議向右繞行"
    }
```

**啟動指令：**

```bash
ssh roy422@140.136.155.5 -p 8022
conda activate depth-v2
cd ~/Depth_Anything_V2/perception_server
uvicorn perception_server:app --host 0.0.0.0 --port 8000
```

**測試指令：**

```bash
curl -X POST "http://140.136.155.5:8000/perceive" \
  -F "image=@test_image.jpg"
```

---

#### Task 2: Go2 實拍校正圖

**目標：** 用 Go2 相機拍攝 1m/2m/3m 標準距離參考圖

**準備工具：**
- [ ] 捲尺
- [ ] 膠帶標記地板
- [ ] 測試物體（紙箱/椅子）

**測試步驟：**

```bash
# 1. 放置物體在標記位置
# 2. Go2 站在起點
# 3. 拍照

ros2 service call /capture_snapshot std_srvs/srv/Trigger

# 4. 複製到本機
scp roy422@192.168.1.200:/tmp/snapshot_latest.jpg ./calibration_1m.jpg
```

**校正記錄表：**

| 實際距離 | DA3 輸出 | 誤差 | 校正係數 |
|---------|---------|------|---------|
| 1.0 m | ___ m | ___ % | |
| 2.0 m | ___ m | ___ % | |
| 3.0 m | ___ m | ___ % | |
| **平均** | | | **___** |

---

#### Task 3: 距離校正驗證

**目標：** 套用校正係數後，誤差 < 20%

**驗證步驟：**

1. 將 `scale_factor` 更新至 `perception_server.py`
2. 重新測試 1m/2m/3m 圖片
3. 確認校正後誤差

---

### 🟡 P1 次要任務

#### Task 4: 錄製 Demo 備案影片

**目標：** 錄製「找水」流程一鏡到底備案影片

> ⚠️ **這是最重要的 Plan B！** 現場若出問題可立即切換播放

**場景設置：**
- 起點：客廳一角
- 障礙物：紙箱（中途）
- 目標物：水瓶（桌上）

**錄製內容：**
1. 使用者語音指令：「Go2，幫我找水」
2. Go2 前進 → 看到障礙物 → 繞行
3. 繼續前進 → 看到水瓶 → 停下
4. 語音回饋：「爺爺，水在前面桌上喔！」

**錄製工具：**
- 手機錄影（追蹤機器狗）
- 螢幕錄影（Kilo Code 對話過程）

---

## ⚠️ 注意事項

### 昨日重要發現

1. **純視覺避障成功率 50-60%** → DA3 整合後目標提升至 80%+
2. **DA3 VRAM 僅 1.34 GB** → 可與 YOLO-World 共存
3. **DA3 推論速度 229 ms** → 滿足 < 500ms 需求

### 今日檢查清單

- [ ] GPU 伺服器 SSH 連線正常
- [ ] Go2 電量 > 50%
- [ ] 準備捲尺 + 膠帶
- [ ] 錄影設備充電

---

## 📝 筆記區

```
=== Task 1: FastAPI Server ===
- 開始時間：
- 結束時間：
- 狀態：
- 筆記：

=== Task 2: Go2 校正圖 ===
- 開始時間：
- 結束時間：
- 狀態：
- 筆記：

=== Task 3: 距離校正 ===
- 開始時間：
- 結束時間：
- 狀態：
- 筆記：

=== Task 4: 備案影片 ===
- 開始時間：
- 結束時間：
- 狀態：
- 筆記：

```

---

## 🏆 今日目標

| 目標 | 驗收標準 | 狀態 |
|------|---------|------|
| FastAPI Server | `/perceive` 正常回應 | ⏳ |
| 校正圖拍攝 | 1m/2m/3m 三張圖 | ⏳ |
| 距離校正 | 誤差 < 20% | ⏳ |
| 備案影片 | 完整流程錄製完成 | ⏳ |

---

## 🔗 相關資源

- [昨日進度 (12/14)](./2025-12-14-dev.md)
- [開發計畫](../../00-overview/開發計畫.md)
- [專題目標](../../00-overview/專題目標.md)
- [Depth Anything V2 指南](../../01-guides/Depth%20Anything%20V2/depth-anything-v2-guide.md)
- [GPU 伺服器指南](../../01-guides/gpu-server-guide.md)

---

**下次更新：** 2025-12-15 晚上

