# 2025-12-15 開發筆記 (W8 Day 1)

**日期：** 2025/12/15（星期日）  
**目標：** W8 感知系統整合啟動 - FastAPI Server + 距離校正  
**前置作業：** W7 視覺閉環 Phase A-D 全部完成 ✅  
**關鍵里程碑：** 2026/1/7 第一階段發表（剩餘 23 天）

---

## ⏱️ 今日時間軸規劃

| 時段 | 任務 | 主要工作 | 預估時間 | 狀態 |
|------|------|---------|---------|------|
| 15:26-15:45 | Task 1 | FastAPI Perception Server | 2 小時 | ✅ 完成 |
| 15:45-15:51 | Task 2 準備 | 校正框架建立 | 10 分鐘 | ✅ 完成 |
| 下午 | Task 2 | Go2 實拍校正圖（1m/2m/3m） | 1.5 小時 | 🔄 進行中 |
| 傍晚 | Task 3 | 距離校正 + 避障建議驗證 | 1.5 小時 | ⏳ |
| 晚上 | Task 4 | 錄製 Demo 備案影片（重要！） | 1 小時 | ⏳ |

**預估總時間：** 5-6 小時

---

## ✅ Task 1: FastAPI Perception Server（已完成）

### 執行記錄

- **開始時間：** 15:26
- **結束時間：** 15:45
- **實際耗時：** 約 20 分鐘
- **狀態：** ✅ 完成

### 建立的檔案

```
perception_server/
├── perception_server.py   # 主程式 (FastAPI + DA3)
├── requirements.txt       # 依賴清單
├── start_server.sh        # 啟動腳本
└── calibration/
    ├── README.md          # 校正 SOP
    └── calibrate.py       # 自動校正腳本
```

### 驗收結果

| 測試項 | 驗收標準 | 結果 | 備註 |
|--------|---------|------|------|
| Server 啟動 | 無報錯 | ✅ Pass | PID: 478866 |
| 模型載入 | VRAM < 10GB | ✅ Pass | **1.34 GB** |
| `/` 健康檢查 | 回傳 status:ok | ✅ Pass | `{"status":"ok","model_loaded":true}` |
| `/perceive` | 回傳 JSON | ✅ Pass | 區域分析 + 避障建議 |
| 推論時間 | < 500ms | ✅ Pass | **291ms** (640x480) |
| `/perceive/summary` | 純文字摘要 | ✅ Pass | LLM 友好格式 |

### API 回應範例

**測試圖片：** `assets/examples/test3.png` (640x480 室內場景)

```json
{
    "left_m": 2.3,
    "center_m": 2.93,
    "right_m": 3.12,
    "front_obstacle_m": 1.19,
    "min_m": 1.07,
    "max_m": 7.31,
    "suggestion": "✅ 前方暢通（1.2m），可安全前進",
    "inference_ms": 291.5,
    "image_size": "640x480"
}
```

**純文字摘要 (`/perceive/summary`)：**

```
[環境感知摘要]
- 左側: 2.3m
- 正前方: 1.19m
- 右側: 3.12m
✅ 前方暢通（1.2m），可安全前進
```

### Code Review 結論

**🟢 優點：**
- 架構清晰，FastAPI 標準結構
- 深度分析使用 `median` 而非 `mean`（更穩健）
- `center_lower + percentile(25)` 抓前方最近障礙的設計很棒
- 避障建議邏輯完整（三種情境覆蓋）

**🟡 待改進（後續優化）：**
- `SCALE_FACTOR = 1.0` → 需 Go2 實拍校正 ⬅️ **最關鍵**
- 缺少 logging 模組
- `perceive_summary` 重複推論（可優化）

### 啟動指令

```bash
# SSH 連線 GPU 伺服器
ssh roy422@140.136.155.5 -p 8022

# 啟動服務
conda activate depth-v2
cd ~/Depth_Anything_V2/Depth-Anything-V2/perception_server
uvicorn perception_server:app --host 0.0.0.0 --port 8000
```

---

## 🔄 Task 2: Go2 實拍校正（進行中）

### 準備工作

- **開始時間：** 15:45
- **狀態：** 🔄 校正框架已建立，等待拍攝

### 已建立：校正自動化工具

**檔案位置：** `perception_server/calibration/`

| 檔案 | 用途 |
|------|------|
| `README.md` | 拍攝 SOP 與記錄表 |
| `calibrate.py` | 自動分析腳本，計算 SCALE_FACTOR |

### 拍攝流程 SOP

**Step 1: 準備場景**
```
1. 用膠帶標記地板 1m / 2m / 3m 位置
2. 在 1m 處放置物體（紙箱/椅子，高度 > 30cm）
```

**Step 2: 拍攝校正圖（在 Mac VM 執行）**
```bash
# 拍攝 1m 圖片
ros2 service call /capture_snapshot std_srvs/srv/Trigger

# 上傳至 GPU 伺服器
scp /tmp/snapshot_latest.jpg \
  roy422@140.136.155.5:~/Depth_Anything_V2/Depth-Anything-V2/perception_server/calibration/calibration_1m.jpg
```

**Step 3: 重複 2m 和 3m**
- 移動物體到 2m → 拍照 → 存為 `calibration_2m.jpg`
- 移動物體到 3m → 拍照 → 存為 `calibration_3m.jpg`

**Step 4: 執行校正分析**
```bash
# 在 GPU 伺服器
cd ~/Depth_Anything_V2/Depth-Anything-V2/perception_server/calibration
conda run -n depth-v2 python calibrate.py
```

### 校正記錄表

| 實際距離 | DA3 front_obstacle_m | 誤差 | 校正係數 |
|---------|---------------------|------|---------|
| 1.0 m | ___ m | ___ % | |
| 2.0 m | ___ m | ___ % | |
| 3.0 m | ___ m | ___ % | |
| **平均** | | | **SCALE_FACTOR = ___** |

---

## ⏳ Task 3: 距離校正驗證

**目標：** 套用 SCALE_FACTOR 後，誤差 < 20%

**步驟：**
1. 更新 `perception_server.py` 中的 `SCALE_FACTOR`
2. 重啟伺服器
3. 重新測試校正圖片
4. 確認校正後誤差

---

## ⏳ Task 4: 錄製 Demo 備案影片

**目標：** 錄製「找水」流程一鏡到底備案影片

> ⚠️ **這是最重要的 Plan B！** 現場若出問題可立即切換播放

**場景設置：**
- 起點：客廳一角
- 障礙物：紙箱（中途）
- 目標物：水瓶（桌上）

**錄製內容：**
1. 使用者語音指令：「Go2，幫我找水」
2. Go2 前進 → 看到障礙物 → 繞行
3. 繼續前進 → 看到水瓶 → 停下
4. 語音回饋：「爺爺，水在前面桌上喔！」

**錄製工具：**
- 手機錄影（追蹤機器狗）
- 螢幕錄影（Kilo Code 對話過程）

---

## ⚠️ 技術筆記

### Perception Server 架構

```mermaid
graph LR
    subgraph GPU["GPU 伺服器 :8000"]
        FastAPI[FastAPI]
        DA3[DA3 ViT-L]
        Analyze[區域分析]
    end
    
    Client[圖片上傳] --> FastAPI
    FastAPI --> DA3
    DA3 --> Analyze
    Analyze --> Response[JSON 回應]
```

### DA3 區域分析邏輯

```python
# 分割為左中右三區（各佔畫面 1/3）
left_region = depth_map[:, :w//3]
center_region = depth_map[:, w//3:2*w//3]
right_region = depth_map[:, 2*w//3:]

# 中央下半部 = 前方最近障礙物
center_lower = depth_map[h//2:, w//3:2*w//3]
front_obstacle = np.percentile(center_lower, 25)  # 取較近距離
```

### 避障決策邏輯

| 條件 | 建議 |
|------|------|
| `front > 1.0m` | ✅ 前方暢通，可前進 |
| `front < 1.0m && right > left` | ⚠️ 建議向右繞行 |
| `front < 1.0m && left > right` | ⚠️ 建議向左繞行 |
| 三面受阻 | 🛑 建議後退或停止 |

---

## 🏆 今日目標進度

| 目標 | 驗收標準 | 狀態 | 備註 |
|------|---------|------|------|
| FastAPI Server | `/perceive` 正常回應 | ✅ 完成 | 291ms / 640x480 |
| Code Review | 程式碼品質確認 | ✅ 完成 | 架構清晰，待校正 |
| 校正框架 | calibrate.py 建立 | ✅ 完成 | 自動計算 SCALE_FACTOR |
| 校正圖拍攝 | 1m/2m/3m 三張圖 | 🔄 進行中 | Go2 已就緒 |
| 距離校正 | 誤差 < 20% | ⏳ | 待拍攝後執行 |
| 備案影片 | 完整流程錄製完成 | ⏳ | |

---

## 📝 筆記區

```
=== Task 1: FastAPI Server ===
- 開始時間：15:26
- 結束時間：15:45
- 狀態：✅ 完成
- 筆記：
  - 使用 Antigravity AI 輔助開發，20 分鐘完成
  - 模型載入 VRAM 僅 1.34 GB（預期內）
  - 推論速度 291ms (640x480)，符合 < 500ms 標準
  - Code Review 通過，架構清晰

=== Task 2: Go2 校正圖 ===
- 開始時間：15:45
- 結束時間：
- 狀態：🔄 進行中
- 筆記：
  - 校正框架已建立 (calibration/)
  - 等待 Go2 拍攝 1m/2m/3m 校正圖
  - calibrate.py 可自動計算 SCALE_FACTOR

=== Task 3: 距離校正 ===
- 開始時間：
- 結束時間：
- 狀態：⏳
- 筆記：

=== Task 4: 備案影片 ===
- 開始時間：
- 結束時間：
- 狀態：⏳
- 筆記：
```

---

## 🔗 相關資源

- [昨日進度 (12/14)](./12-14.md)
- [開發計畫](../開發計畫.md)
- [專題目標](../專案目標.md)
- [Perception Server 程式碼](../../perception_server/perception_server.py)
- [校正工具](../../perception_server/calibration/)

---

**下次更新：** 2025-12-15 晚上（Task 2-4 完成後）

